{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_features, num_timesteps, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.num_features = num_features\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.GRU(num_features, hidden_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        :params inputs: Input time series data of shape(batch_size, num_timesteps, num_features)\n",
    "        \"\"\"\n",
    "        inputs = inputs.permute(1, 0, 2)\n",
    "        \n",
    "        out, last_h = self.rnn(inputs)\n",
    "\n",
    "        out = out.permute(1, 0, 2)\n",
    "        last_h = last_h.view(-1, self.hidden_size)\n",
    "        \n",
    "        return out, last_h\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_timesteps_out, hidden_size, num_features_out, concat=True):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.num_timesteps_out = num_timesteps_out\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_features_out = num_features_out\n",
    "        self.concat = concat\n",
    "        \n",
    "        if concat:\n",
    "            self.rnn_cell = nn.GRUCell(hidden_size*2, hidden_size*2)\n",
    "            self.linear = nn.Linear(hidden_size*2, num_features_out)\n",
    "        else:\n",
    "            self.rnn_cell = nn.GRUCell(hidden_size, hidden_size)\n",
    "            self.linear = nn.Linear(hidden_size, num_features_out)    \n",
    "        \n",
    "    def forward(self, encoder_ts_hid, encoder_features_hid):\n",
    "        '''\n",
    "        :param encoder_ts_hid: (batch_size, hidden_size)\n",
    "        :param encoder_features_hid: (batch_size, hidden_size)\n",
    "        '''\n",
    "        decoder_out = []\n",
    "        if self.concat:\n",
    "            hid = torch.cat([encoder_ts_hid, encoder_features_hid], dim=-1)\n",
    "        else:\n",
    "            hid = encoder_ts_hid + encoder_features_hid\n",
    "        \n",
    "        for step in range(self.num_timesteps_out):\n",
    "            if step == 0:\n",
    "                out = self.linear(hid)\n",
    "            else:\n",
    "                hid = self.rnn_cell(hid,hid)\n",
    "                out = self.linear(hid)\n",
    "            decoder_out.append(out)\n",
    "        \n",
    "        decoder_out = torch.cat(decoder_out,dim=-1)\n",
    "        return decoder_out\n",
    "    \n",
    "class Project(nn.Module):\n",
    "    def __init__(self, num_features, hidden_size, dropout=0.5):\n",
    "        super(Project, self).__init__()\n",
    "        \n",
    "        self.num_features = num_features\n",
    "        self.linear_1 = nn.Linear(num_features, hidden_size)\n",
    "        self.dropout_1 = nn.Dropout(p=dropout)\n",
    "        self.bn_1 = nn.BatchNorm1d(hidden_size)\n",
    "        \n",
    "        self.linear_2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.dropout_2 = nn.Dropout(p=dropout)\n",
    "        self.bn_2 = nn.BatchNorm1d(hidden_size)        \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        :params inputs: Input static features of shape(batch_size, num_features)\n",
    "        \"\"\"\n",
    "        fc = self.bn_1(self.dropout_1(self.linear_1(inputs)))\n",
    "        fc = self.bn_2(self.dropout_2(self.linear_2(fc)))\n",
    "\n",
    "        return fc\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.Tensor(hidden_size,))\n",
    "        nn.init.uniform_(self.weight)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        :params inputs: Input hidden features of shape(atten_dim, hidden_size)\n",
    "        \"\"\"\n",
    "        epsilon = 1e-10\n",
    "        e_ij = torch.tanh(torch.matmul(inputs, self.weight.view(-1,1)))\n",
    "        a = torch.exp(e_ij)\n",
    "        a /= torch.sum(a,dim=-2,keepdim=True) + epsilon\n",
    "        weighted_input =inputs * a\n",
    "        return torch.sum(weighted_input, axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PropagationNet(nn.Module): \n",
    "    def __init__(self, num_timesteps_in=14,\n",
    "                     num_timesteps_out=7,\n",
    "                     ts_num_features=3,\n",
    "                     weather_num_features=11,\n",
    "                     containment_num_features=18,\n",
    "                     population_num_features=11,\n",
    "                     healthcare_num_features=18,\n",
    "                     hidden_size=64):\n",
    "        super(PropagationNet, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.ts_encoder = Encoder(ts_num_features,num_timesteps_in,hidden_size)\n",
    "        \n",
    "        self.weather_encoder = Encoder(weather_num_features,num_timesteps_in,hidden_size)\n",
    "        self.containment_encoder = Encoder(containment_num_features,num_timesteps_in,hidden_size)\n",
    "        \n",
    "        self.population_project = Project(population_num_features,hidden_size)\n",
    "        self.healthcare_project = Project(healthcare_num_features,hidden_size)\n",
    "        \n",
    "        self.attention = SelfAttention(hidden_size)\n",
    "        self.decoder = Decoder(num_timesteps_out,hidden_size,ts_num_features)\n",
    "        \n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        :params inputs: list of \n",
    "        ts_input (batch_size, timesteps_in, ts_num_features)\n",
    "        weather_input (batch_size, timesteps_in, weather_num_features)\n",
    "        containment_input (batch_size, timesteps_in, containment_num_features)\n",
    "        \n",
    "        population_input (batch_size, population_num_features)\n",
    "        healthcare_input (batch_size, healthcare_num_features)\n",
    "        \"\"\"\n",
    "        assert(len(inputs)==5)\n",
    "        ts, weather_ts, containment_ts, population, healthcare = inputs\n",
    "\n",
    "        _, encoder_ts_hid = self.ts_encoder(ts)\n",
    "        \n",
    "        _, encoder_weather_hid = self.weather_encoder(weather_ts)\n",
    "        _, encoder_containment_hid = self.containment_encoder(containment_ts)\n",
    "        \n",
    "        project_population_hid = self.population_project(population)\n",
    "        project_healthcare_hid = self.healthcare_project(healthcare)\n",
    "        \n",
    "        \n",
    "        features_hid = torch.cat([encoder_weather_hid.view(-1,1,self.hidden_size),\n",
    "                                     encoder_containment_hid.view(-1,1,self.hidden_size),\n",
    "                                     project_population_hid.view(-1,1,self.hidden_size),\n",
    "                                     project_healthcare_hid.view(-1,1,self.hidden_size)], \n",
    "                                    dim = 1)\n",
    "        \n",
    "        features_att = self.attention(features_hid)\n",
    "        \n",
    "        outs = self.decoder(encoder_ts_hid, features_att)\n",
    "        \n",
    "        return features_hid, outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "class COVID_Dataset(Dataset):\n",
    "    def __init__(self, data, y=None):\n",
    "        super(COVID_Dataset, self).__init__()\n",
    "        \n",
    "        self.ts = data[0]\n",
    "        self.weather = data[1]\n",
    "        self.policy = data[2]\n",
    "        self.population = data[3]\n",
    "        self.healthcare = data[4]\n",
    "        \n",
    "        self.y = y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.y is not None:\n",
    "            return [self.ts[index],self.weather[index],self.policy[index],self.population[index],self.healthcare[index]],self.y[index]\n",
    "        return self.ts[index],self.weather[index],self.policy[index],self.population[index],self.healthcare[index]\n",
    " \n",
    "    def __len__(self):\n",
    "        return self.ts.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "class COVID_Loss(nn.Module):\n",
    "    \n",
    "    def __init__(self, reg_weight=0.5):\n",
    "        super(COVID_Loss, self).__init__()\n",
    "        self.reg_weight = reg_weight\n",
    "        \n",
    "    def forward(self, predictions, actuals):\n",
    "        hid, preds = predictions\n",
    "        reg = torch.mean(torch.sum(hid * hid, dim=-1), dim=-1)\n",
    "        mae = nn.L1Loss()(preds,torch.log1p_(actuals))\n",
    "        \n",
    "        return reg *self.reg_weight + mae * (1 - self.reg_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_y = pd.read_pickle('../features/train_set.5.7.pkl')\n",
    "test, test_y = pd.read_pickle('../features/test_set.5.7.pkl')\n",
    "countries = pd.read_pickle('../features/countries.5.7.pkl')\n",
    "\n",
    "feautures_list = pd.read_pickle('../features/feature_list.5.7.pkl')\n",
    "\n",
    "dtrain = COVID_Dataset(train,train_y)\n",
    "dtest = COVID_Dataset(test,test_y)\n",
    "train_loader = DataLoader(dtrain, batch_size=64,shuffle=True)\n",
    "test_loader = DataLoader(dtest, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 11, 18, 18, 11)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feautures_list[0]),len(feautures_list[1]),len(feautures_list[2]),len(feautures_list[3]),len(feautures_list[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '../results/exp-01/'\n",
    "initial_checkpoint = None\n",
    "os.makedirs(out_dir +'/checkpoint', exist_ok=True)\n",
    "net = PropagationNet().cuda()\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, net.parameters()),lr=0.0003, weight_decay=0.01)\n",
    "checkpoint = {\n",
    "    'model': net.state_dict(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "if initial_checkpoint is not None:\n",
    "    checkpoint = torch.load(inital_checkpoint)\n",
    "    net.load_state_dict(initial_checkpoint['model'])\n",
    "    print('load model from', initial_checkpoint)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhgao/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf92a11a31d546a783191bdd43ea5685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=70.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhgao/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:88: UserWarning: Using a target size (torch.Size([64, 7, 3])) that is different to the input size (torch.Size([64, 49])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (49) must match the size of tensor b (3) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-266-43cd252ebecb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtruth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtruth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-261-d5816bacf1b0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, predictions, actuals)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mhid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhid\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mmae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL1Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog1p_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactuals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_weight\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmae\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36ml1_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2509\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2510\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2511\u001b[0;31m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2512\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2513\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (49) must match the size of tensor b (3) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "criterion = COVID_Loss(reg_weight=0.5)\n",
    "loss_meter = []\n",
    "for epoch in range(epochs):\n",
    "    net.train()\n",
    "    loss_meter = []\n",
    "    for inputs, truth in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = [item.float().cuda() for item in inputs]\n",
    "        truth = truth.float().cuda()\n",
    "        logit = net(inputs)\n",
    "        loss  = criterion(logit, truth)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_meter.append(loss.item())\n",
    "        \n",
    "    train_loss = np.mean(loss_meter)\n",
    "    net.eval()\n",
    "\n",
    "    if False:\n",
    "        #print('validation summmary: {}_{}'.format(val_loss,val_smape_loss))\n",
    "        torch.save(checkpoint,out_dir +'/checkpoint/epoch_%02d_val_group_smape_%s_model.pth'%(epoch, val_str))\n",
    "        print('\\n save model to /checkpoint/epoch_%02d_val_group_smape_%s_model.pth'%(epoch,val_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 4, 64]), torch.Size([64, 49]), torch.Size([64, 7, 3]))"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit[0].shape, logit[1].shape,truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
